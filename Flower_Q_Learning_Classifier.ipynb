{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lqu54fRTCVMl",
        "outputId": "f20faf7f-9f19-465f-b850-4e1724081aca"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0A54xCYjAk6D",
        "outputId": "e7b340c7-695d-4fc8-9a8e-29952c971110"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting features...\n",
            "Quantizing features...\n",
            "Starting training...\n",
            "Completed episode 0, epsilon: 0.9950\n",
            "Completed episode 1000, epsilon: 0.0100\n",
            "Completed episode 2000, epsilon: 0.0100\n",
            "Completed episode 3000, epsilon: 0.0100\n",
            "Completed episode 4000, epsilon: 0.0100\n",
            "Completed episode 5000, epsilon: 0.0100\n",
            "Completed episode 6000, epsilon: 0.0100\n",
            "Completed episode 7000, epsilon: 0.0100\n",
            "Completed episode 8000, epsilon: 0.0100\n",
            "Completed episode 9000, epsilon: 0.0100\n",
            "Testing...\n",
            "Accuracy: 98.01%\n",
            "Precision: 98.02%\n",
            "Number of unique states for group 0: 1371\n",
            "Average Q values for group 0: 39.24625444293572\n",
            "Number of unique states for group 1: 623\n",
            "Average Q values for group 1: 39.9999999999992\n",
            "Number of unique states for group 2: 625\n",
            "Average Q values for group 2: 39.9999999999992\n",
            "Number of unique states for group 3: 759\n",
            "Average Q values for group 3: 39.9999999999992\n"
          ]
        }
      ],
      "source": [
        "from collections import defaultdict\n",
        "import numpy as np\n",
        "import cv2\n",
        "import glob\n",
        "from sklearn.cluster import KMeans\n",
        "from sklearn.metrics import accuracy_score, precision_score\n",
        "\n",
        "\n",
        "\n",
        "folders = {\n",
        "    'daisy': r'/content/drive/MyDrive/flower_photos/daisy/*.jpg',\n",
        "    'dandelion': r'/content/drive/MyDrive/flower_photos/dandelion/*.jpg',\n",
        "    'roses': r'/content/drive/MyDrive/flower_photos/roses/*.jpg',\n",
        "    'sunflowers': r'/content/drive/MyDrive/flower_photos/sunflowers/*.jpg',\n",
        "    'tulips': r'/content/drive/MyDrive/flower_photos/tulips/*.jpg'\n",
        "}\n",
        "\n",
        "\n",
        "images = []\n",
        "labels = []\n",
        "label_mapping = {'daisy': 0, 'dandelion': 1, 'roses': 2, 'sunflowers': 3, 'tulips': 4}\n",
        "\n",
        "for label, folder_path in folders.items():\n",
        "    for img_path in glob.glob(folder_path):\n",
        "        img = cv2.imread(img_path)\n",
        "        if img is not None:\n",
        "            images.append(img)\n",
        "            labels.append(label_mapping[label])\n",
        "\n",
        "\n",
        "def extract_features(image):\n",
        "    image = cv2.resize(image, (128, 128))\n",
        "\n",
        "    hsv = cv2.cvtColor(image, cv2.COLOR_BGR2HSV)\n",
        "    color_features = cv2.mean(hsv)[:3]\n",
        "\n",
        "    gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
        "    edges = cv2.Canny(gray, 100, 200)\n",
        "    edge_features = cv2.mean(edges)[:1]\n",
        "\n",
        "    return np.concatenate([color_features, edge_features])\n",
        "\n",
        "print(\"Extracting features...\")\n",
        "features = np.array([extract_features(img) for img in images])\n",
        "\n",
        "n_clusters = 3000\n",
        "print(\"Quantizing features...\")\n",
        "kmeans = KMeans(n_clusters=n_clusters, n_init=10)\n",
        "quantized_features = kmeans.fit_transform(features)\n",
        "\n",
        "states = np.argmin(quantized_features, axis=1)\n",
        "\n",
        "group_mapping = {\n",
        "    'daisy': 0,\n",
        "    'dandelion': 0,\n",
        "    'roses': 1,\n",
        "    'sunflowers': 2,\n",
        "    'tulips': 3\n",
        "}\n",
        "\n",
        "num_actions = len(label_mapping)\n",
        "learning_rate = 0.1\n",
        "discount_factor = 0.95\n",
        "epsilon_start = 1\n",
        "epsilon_end = 0.01\n",
        "epsilon_decay = 0.995\n",
        "episodes = 10000\n",
        "\n",
        "q_tables = {\n",
        "    0: defaultdict(lambda: np.zeros(num_actions)),\n",
        "    1: defaultdict(lambda: np.zeros(num_actions)),\n",
        "    2: defaultdict(lambda: np.zeros(num_actions)),\n",
        "    3: defaultdict(lambda: np.zeros(num_actions))\n",
        "}\n",
        "\n",
        "print(\"Starting training...\")\n",
        "epsilon = epsilon_start\n",
        "for episode in range(episodes):\n",
        "    for state, true_label in zip(states, labels):\n",
        "\n",
        "        group = group_mapping[list(label_mapping.keys())[true_label]]\n",
        "        q_table = q_tables[group]\n",
        "\n",
        "        if np.random.rand() < epsilon:\n",
        "            action = np.random.randint(num_actions)\n",
        "        else:\n",
        "            action = np.argmax(q_table[state])\n",
        "\n",
        "        if action == true_label:\n",
        "            reward = 2\n",
        "        elif abs(action - true_label) == 1:\n",
        "            reward = 0.5\n",
        "        else:\n",
        "            reward = -1\n",
        "\n",
        "        next_state = state\n",
        "\n",
        "        next_max = np.max(q_table[next_state])\n",
        "        q_table[state][action] += learning_rate * (reward + discount_factor * next_max - q_table[state][action])\n",
        "\n",
        "    epsilon = max(epsilon_end, epsilon * epsilon_decay)\n",
        "\n",
        "    if episode % 1000 == 0:\n",
        "        print(f\"Completed episode {episode}, epsilon: {epsilon:.4f}\")\n",
        "\n",
        "print(\"Testing...\")\n",
        "y_pred = []\n",
        "for state, true_label in zip(states, labels):\n",
        "    group = group_mapping[list(label_mapping.keys())[true_label]]\n",
        "    q_table = q_tables[group]\n",
        "    action = np.argmax(q_table[state])\n",
        "    y_pred.append(action)\n",
        "\n",
        "accuracy = accuracy_score(labels, y_pred)\n",
        "precision = precision_score(labels, y_pred, average='weighted')\n",
        "\n",
        "print(f'Accuracy: {accuracy * 100:.2f}%')\n",
        "print(f'Precision: {precision * 100:.2f}%')\n",
        "\n",
        "for group, q_table in q_tables.items():\n",
        "    print(f'Number of unique states for group {group}: {len(q_table)}')\n",
        "    print(f'Average Q values for group {group}: {np.mean([np.max(q) for q in q_table.values()])}')\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from collections import defaultdict\n",
        "import cv2\n",
        "import glob\n",
        "from sklearn.metrics import accuracy_score, precision_score\n",
        "\n",
        "\n",
        "folders = {\n",
        "    'daisy': r'/content/drive/MyDrive/flower_photos/daisy/*.jpg',\n",
        "    'dandelion': r'/content/drive/MyDrive/flower_photos/dandelion/*.jpg',\n",
        "    'roses': r'/content/drive/MyDrive/flower_photos/roses/*.jpg',\n",
        "    'sunflowers': r'/content/drive/MyDrive/flower_photos/sunflowers/*.jpg',\n",
        "    'tulips': r'/content/drive/MyDrive/flower_photos/tulips/*.jpg'\n",
        "}\n",
        "\n",
        "\n",
        "def load_images(folder_path, label):\n",
        "    images = []\n",
        "    for img_path in glob.glob(folder_path):\n",
        "        img = cv2.imread(img_path)\n",
        "        if img is not None:\n",
        "            img_resized = cv2.resize(img, (250, 250))\n",
        "            hsv = cv2.cvtColor(img_resized, cv2.COLOR_BGR2HSV)\n",
        "            feature_vector = hsv.flatten()[:70]\n",
        "            images.append((feature_vector, label))\n",
        "    return images\n",
        "\n",
        "data = []\n",
        "label_mapping = {label: idx for idx, label in enumerate(folders.keys())}\n",
        "for label, folder in folders.items():\n",
        "    data.extend(load_images(folder, label_mapping[label]))\n",
        "\n",
        "\n",
        "features, labels = zip(*data)\n",
        "features = np.array(features)\n",
        "labels = np.array(labels)\n",
        "\n",
        "\n",
        "\n",
        "num_states = features.shape[1]\n",
        "num_actions = len(label_mapping)\n",
        "learning_rate = 0.1\n",
        "discount_factor = 0.95\n",
        "epsilon_start = 0.9\n",
        "epsilon_end = 0.1\n",
        "epsilon_decay = 0.995\n",
        "episodes = 1000\n",
        "\n",
        "\n",
        "q_table = defaultdict(lambda: np.zeros(num_actions))\n",
        "\n",
        "\n",
        "def choose_action(state, epsilon):\n",
        "    if np.random.rand() < epsilon:\n",
        "        return np.random.randint(num_actions)\n",
        "    else:\n",
        "        return np.argmax(q_table[state])\n",
        "\n",
        "\n",
        "def update_q_table(state, action, reward, next_state):\n",
        "    best_next_action = np.argmax(q_table[next_state])\n",
        "    td_target = reward + discount_factor * q_table[next_state][best_next_action]\n",
        "    td_error = td_target - q_table[state][action]\n",
        "    q_table[state][action] += learning_rate * td_error\n",
        "\n",
        "\n",
        "epsilon = epsilon_start\n",
        "for episode in range(episodes):\n",
        "    for feature, true_label in zip(features, labels):\n",
        "        state = tuple(np.round(feature, 2))\n",
        "        action = choose_action(state, epsilon)\n",
        "        reward = 2 if action == true_label else -1\n",
        "        next_state = state\n",
        "        update_q_table(state, action, reward, next_state)\n",
        "\n",
        "\n",
        "    epsilon = max(epsilon_end, epsilon * epsilon_decay)\n",
        "\n",
        "\n",
        "    if episode % 100 == 0:\n",
        "        print(f\"Episode {episode}: epsilon = {epsilon:.3f}\")\n",
        "\n",
        "\n",
        "y_pred = []\n",
        "for feature in features:\n",
        "    state = tuple(np.round(feature, 2))\n",
        "    action = np.argmax(q_table[state])\n",
        "    y_pred.append(action)\n",
        "\n",
        "\n",
        "accuracy = accuracy_score(labels, y_pred)\n",
        "precision = precision_score(labels, y_pred, average='weighted')\n",
        "print(f'Accuracy: {accuracy * 100:.2f}%')\n",
        "print(f'Precision: {precision * 100:.2f}%')\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6wxAbhai8aS_",
        "outputId": "b6430be2-97b2-4fd1-9426-c858355651b7"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Episode 0: epsilon = 0.895\n",
            "Episode 100: epsilon = 0.542\n",
            "Episode 200: epsilon = 0.329\n",
            "Episode 300: epsilon = 0.199\n",
            "Episode 400: epsilon = 0.121\n",
            "Episode 500: epsilon = 0.100\n",
            "Episode 600: epsilon = 0.100\n",
            "Episode 700: epsilon = 0.100\n",
            "Episode 800: epsilon = 0.100\n",
            "Episode 900: epsilon = 0.100\n",
            "Accuracy: 97.06%\n",
            "Precision: 97.21%\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}